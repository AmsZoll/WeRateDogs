{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                                 Wrangle Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Data Wrangling process consists of:  \n",
    "\n",
    "1.   Gathering the data\n",
    "2.   Assessing the data\n",
    "3.   Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Step One\n",
    "- As I mentioned above, the analysis stages are divided into three main stages The first stage was downloading  a file    manually From Udacity Website  and be able to open a csv file. In this case the file was called  twitter_archive_enhanced.csv . using the Pandas library And upload the prediction image file in TSV formats.the final was need  to query Twitterâ€™s API and use a Python library called Tweepy to obtain further data on the tweets in the archive file using the tweet id. The Tweepy library returned the data in json format, from which it was possible to iterate through and append data to a file as a list of dictionaries and then a pandas data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step Two \n",
    "- The three saved data frames were then assessed visually inside a jupyter notebook with pandas. This  allowed quick scanning through the rows and use of filters to identify areas for more detailed Check . Following this a programmatic assessment was made inside jupyter with pandas using the following functions, df.info(), df.head(), df.value_counts() . \n",
    "The datasets were accessed under two criteria, quality and tidiness. \n",
    "Quality refers to issues related to the content of the data, sometimes called dirty data.. \n",
    "Tidiness refers to issues related to the structure of the data, sometimes called messy data.. After assessing the three datasets, it was decided to marge them into a single data frame. the assment result as fowllowing \n",
    "## Quality\n",
    "\n",
    "- 1-  incorrect data type : timestamp\n",
    "- 2- Five columns is mostly have null values( col #1,2,6,7,8).\n",
    "- 3- Fix nondescriptive column headers (p1 , p1_conf,etc).\n",
    "- 4- Source column is unreadable.\n",
    "- 5- There are 181 retweet and 78 reply we do't need them for this analysis.\n",
    "- 6- more than 745 dogs have been assigned the name as None/a.\n",
    "- 7- inaccurate data and incorrect data type in rating  rating numerator.\n",
    "- 8- inaccurate data and incorrect data type in rating denominator.\n",
    "- 9- changing the values in confidence level  to percentages\n",
    "\n",
    "## Tidiness\n",
    "- 1- Doggo, puppo, etc. should be placed in one column because these are the same categorical data\n",
    "- 2- we should add favourate count into twitter data\n",
    "- 3- we should also merge image prediction file too\n",
    "- 4- Dogs name has Underscores that makes data untidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step three \n",
    "The final step iis cleaning the data for quality and tidiness issues. The cleaning followed the standard process of define, code and test for each of the issues . \n",
    "\n",
    "Most of the cleaning was performed using programmatic tools, such as  pandas built-in functions ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In conclusion\n",
    "- this process provides many services such as deep understanding of data, high level of quality and organizational structure, to help in better future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
